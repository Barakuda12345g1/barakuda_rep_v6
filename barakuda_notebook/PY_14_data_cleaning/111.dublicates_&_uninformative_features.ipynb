{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa072937",
   "metadata": {},
   "source": [
    "# Импорт библиотек и подгрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8767c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки для работы с данными, математических преобразований\n",
    "# и для визуализации\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# читаем в переменную датасет для работы с данными\n",
    "sber_data = pd.read_csv('data/sber_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06399e38",
   "metadata": {},
   "source": [
    "# Дубликаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba938cce",
   "metadata": {},
   "source": [
    "## .duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cdb07",
   "metadata": {},
   "source": [
    "    .subset - список из тех прризнаков, которые булдут проверяться. По умолчанию проверяет все признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258d09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число найденных дубликатов: 562\n"
     ]
    }
   ],
   "source": [
    "# утверждаем, что дубликатов нет\n",
    "sber_data['id'].nunique() == sber_data.shape[0]\n",
    "# создаем список для хранения там названия признаков без признака 'id'\n",
    "dupl_columns = list(sber_data.columns)\n",
    "# удаляем столбец 'id', потому что там все значения уникальные\n",
    "dupl_columns.remove('id')\n",
    "# подготавливаем маску для фильтрации, \n",
    "# булевые значения True будут остваленны в  исходном датафрейме\n",
    "mask = sber_data.duplicated(subset=dupl_columns)\n",
    "# фильтруем таблицу\n",
    "sber_duplicates = sber_data[mask]\n",
    "print(f'Число найденных дубликатов: {sber_duplicates.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d74caf",
   "metadata": {},
   "source": [
    "## .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655bb25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результирующее число записей: 29909\n"
     ]
    }
   ],
   "source": [
    "# удаляем повторяющиеся записи из таблицы\n",
    "sber_dedupped = sber_data.drop_duplicates(subset=dupl_columns)\n",
    "# сообщаем о количестве оставшихся записей\n",
    "print(f'Результирующее число записей: {sber_dedupped.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12c279",
   "metadata": {},
   "source": [
    "# Неинформативные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828d38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 100.0% уникальных значений\n",
      "oil_chemistry_raion : 99.03% одниковх значений\n",
      "railroad_terminal_raion : 96.27% одниковх значений\n",
      "nuclear_reactor_raion : 97.17% одниковх значений\n",
      "big_road1_1line : 97.44% одниковх значений\n",
      "mosque_count_1000 : 98.08% одниковх значений\n",
      "********************************************************************************\n",
      "Реультирующее число признаков: 55\n"
     ]
    }
   ],
   "source": [
    "# созданяю список неиформативных признавков\n",
    "low_information_cols = []\n",
    "# рассматриваю каждый столбец отдельно и в заисимости от его \n",
    "# зарактреистик выбираю помезатьего в список неинформативных столбцов или нет\n",
    "for col in sber_data.columns:\n",
    "    # проверяю столбец на уникальность и\n",
    "    # нахожу уникальное значение с самой максмальной частотой \n",
    "    top_freq = sber_data[col].value_counts(normalize=True).max()\n",
    "    # проверяю столбец на количество уникальных наблюдений \n",
    "    # в процентном соотношении\n",
    "    nunique_ratio = sber_data[col].nunique() / sber_data[col].count()\n",
    "    # если количество одинковых наблдений больше 0.95, \n",
    "    # то добавляю их в список признаков для удаления\n",
    "    if top_freq > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        # понято печатаем ответ, столбец и число одинаковых значений в процентах\n",
    "        print(f'{col} : {round(top_freq * 100, 2)}% одниковх значений')\n",
    "    # если уникальных значений в столбце больше порога в 0.95, \n",
    "    # то отправляем название столбца в список для удлаения\n",
    "    if nunique_ratio > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        print(f'{col} : {round(nunique_ratio * 100, 2)}% уникальных значений')\n",
    "print('*' * 80)\n",
    "# удаляем из исходной таблицы признаки \n",
    "# при помощи списка low_information_cols\n",
    "information_sber_data = sber_data.drop(low_information_cols, axis=1)    \n",
    "# выводим результат \n",
    "print(f'Реультирующее число признаков: {information_sber_data.shape[1]}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
